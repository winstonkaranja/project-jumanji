{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U ipykernel numpy matplotlib scikit-image pandas langchain boto3 tifffile numpy langchain-openai pillow langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a field of corn plants. The corn stalks are tall and green, with some ears of corn visible among the leaves. The background features a blue sky with some clouds, indicating a bright day. The overall scene appears to be a healthy corn crop.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import getpass\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.tools import tool\n",
    "import openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.schema.messages import SystemMessage\n",
    "from PIL import Image\n",
    "import base64\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "class AgentSchema():\n",
    "    aerial_photo: str\n",
    "    ground_photo: str\n",
    "\n",
    "\n",
    "\n",
    "def read_image_from_s3(bucket_name, key):\n",
    "    \"\"\"\n",
    "    Download an image from S3 and load it based on its file type.\n",
    "    Supports TIFF (.tif, .tiff) and JPEG (.jpg, .jpeg) formats.\n",
    "    \n",
    "    For TIFF images, the image is returned as a NumPy array (float32).\n",
    "    For JPEG images, the image is returned as a PIL.Image instance.\n",
    "    \"\"\"\n",
    "    # Initialize S3 client\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    # Get the object from S3\n",
    "    response = s3_client.get_object(Bucket=bucket_name, Key=key)\n",
    "    image_data = response['Body'].read()\n",
    "    \n",
    "    # Create a file-like object from the data\n",
    "    file_obj = BytesIO(image_data)\n",
    "    \n",
    "    # Check file extension to decide how to load the image\n",
    "    key_lower = key.lower()\n",
    "    if key_lower.endswith(('.tif', '.tiff')):\n",
    "        # Load TIFF image using tifffile and convert to float32 NumPy array\n",
    "        image = tiff.imread(file_obj).astype(np.float32)\n",
    "    elif key_lower.endswith(('.jpg', '.jpeg')):\n",
    "        # Load JPEG image using PIL\n",
    "        image = Image.open(file_obj)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported image format. Please use TIFF or JPEG.\")\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# api_key = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
    "\n",
    "# Set the API key as an environment variable\n",
    "os.environ.clear()\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "# Load the Image and Convert to Base64\n",
    "def encode_image_from_s3(bucket_name, key):\n",
    "    \"\"\"\n",
    "    Load an image from S3 (using the shared read_image_from_s3 function) and encode it as a Base64 string.\n",
    "    This function supports only JPEG images for encoding.\n",
    "    \"\"\"\n",
    "    # Ensure the file is a JPEG based on its S3 key extension.\n",
    "    key_lower = key.lower()\n",
    "    if not key_lower.endswith(('.jpg', '.jpeg')):\n",
    "        raise ValueError(\"Only JPEG images can be encoded to Base64.\")\n",
    "    \n",
    "    # Load the image using the shared read_image_from_s3 function.\n",
    "    image = read_image_from_s3(bucket_name, key)\n",
    "    \n",
    "    # Ensure the returned image is a PIL Image instance (as expected for JPEGs).\n",
    "    if not isinstance(image, Image.Image):\n",
    "        raise ValueError(\"Expected a JPEG image (as PIL Image), but received a different type.\")\n",
    "    \n",
    "    # Save the PIL image to a BytesIO buffer.\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=\"JPEG\")\n",
    "    buffer.seek(0)\n",
    "    \n",
    "    # Encode the image bytes to Base64.\n",
    "    image_base64 = base64.b64encode(buffer.read()).decode(\"utf-8\")\n",
    "    return image_base64\n",
    "\n",
    "# Path to the Image\n",
    "bucket_name = 'qijaniproductsbucket'\n",
    "key = \"Maize.jpg\"\n",
    "image_base64 = encode_image_from_s3(bucket_name, key)\n",
    "\n",
    "# Define the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Prepare the Message with Image\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are an AI that analyzes images.\"),\n",
    "    HumanMessage(content=[\n",
    "        {\"type\": \"text\", \"text\": \"What do you see in this image?\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"}}\n",
    "    ])\n",
    "]\n",
    "\n",
    "# Analyze the Image\n",
    "response = llm(messages)\n",
    "print(response.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final agent decision: {'input': 'Image: 20180627_seq_50m_NC.tif', 'output': 'The NDVI output indicates the presence of vegetation, with values typically ranging from -1 to 1. Positive values (especially those above 0.2) suggest healthy vegetation, while values below 0 indicate non-vegetated surfaces.\\n\\nGiven the NDVI values produced from the image, it appears to show significant areas of healthy vegetation, which is characteristic of real farmland.\\n\\nTherefore, I will accept the image as indicating real farmland.'}\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------\n",
    "# Step 2: Wrap NDVI Check as a LangChain Tool for Aerial Photo\n",
    "# -------------------------------------------------------\n",
    "from numpy import ndarray\n",
    "from compute import full_image_processing_pipeline\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------------\n",
    "# Global Parameters for the Pipeline\n",
    "# -------------------------------\n",
    "RADIOMETRIC_PARAMS = {\n",
    "    'gain': [0.012, 0.012, 0.012, 0.012, 0.012],\n",
    "    'offset': [0, 0, 0, 0, 0],\n",
    "    'sunelev': 60.0,\n",
    "    'edist': 1.0,\n",
    "    'Esun': [1913, 1822, 1557, 1317, 1074],\n",
    "    'blackadjust': 0.01,\n",
    "    'low_percentile': 1\n",
    "}\n",
    "NOISE_METHOD = 'median'\n",
    "NOISE_KERNEL_SIZE = 3\n",
    "SIGMA = 1.0\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Step 2: Wrap NDVI Check as a LangChain Tool for Aerial Photo\n",
    "# -------------------------------------------------------\n",
    "@tool\n",
    "def check_ndvi(\n",
    "    # Example S3 file reading (ensure read_tiff_from_s3 is defined and imported)\n",
    "    key: str, \n",
    "    bucket_name: str = \"qijaniproductsbucket\",\n",
    "    red_band_index: int = 2, \n",
    "    nir_band_index: int = 4,\n",
    "    radiometric_params: dict = RADIOMETRIC_PARAMS,\n",
    "    noise_method: str = NOISE_METHOD,\n",
    "    noise_kernel_size: int = NOISE_KERNEL_SIZE,\n",
    "    sigma: float = SIGMA,\n",
    "    save_path: str = \"ndvi_output.jpg\"\n",
    ") -> tuple[np.ndarray, str]:\n",
    "    \"\"\"\n",
    "    Given an aerial multispectral image (as a nested list) with pixel values in [0,1],\n",
    "    compute the NDVI using the provided red and NIR band indices.\n",
    "    Returns:\n",
    "    - Processed NDVI array (NumPy array)\n",
    "    - Path to the saved NDVI image file\n",
    "    \"\"\"\n",
    "\n",
    "    image = read_image_from_s3(bucket_name, key)\n",
    "\n",
    "    # Run NDVI processing pipeline\n",
    "    ndvi_noise_reduced, _ = full_image_processing_pipeline(\n",
    "        image,\n",
    "        radiometric_params, \n",
    "        detector_type='ORB',\n",
    "        noise_method=noise_method, \n",
    "        noise_kernel_size=noise_kernel_size, \n",
    "        sigma=sigma,\n",
    "        nir_band_index=nir_band_index, \n",
    "        red_band_index=red_band_index, \n",
    "        visualize=False,\n",
    "        use_parallel_noise_reduction=False\n",
    "    )\n",
    "\n",
    "    # Plot and save the NDVI image\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(ndvi_noise_reduced, cmap='RdYlGn')\n",
    "    plt.colorbar(label='NDVI Value')\n",
    "    plt.title(\"NDVI Analysis\")\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    return ndvi_noise_reduced, save_path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Initialize the LangChain Agent Using GPT (OpenAI)\n",
    "# -------------------------------------------------------\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "\n",
    "# Include the NDVI checking tool in our list of tools.\n",
    "tools = [check_ndvi]\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Run the Agent with a Prompt for the Aerial Photo Pipeline\n",
    "# -------------------------------------------------------\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "    (\"system\", \"You are an agricultural image evaluator. Given the following multispectral aerial image key\"\n",
    "    \"use check_ndvi tool to perform ndvi \"\n",
    "    \"determine if the NDVI figure produced in the output file save path indicate real farmland. \"\n",
    "    \"then accept the image; otherwise, reject it. Keep output short and precise, either \"\"Accept\"\" or \"\"Reject\"\"\\n\\n\"),\n",
    "    \n",
    "    (\"human\", \"Image: \" + str(key)),\n",
    "\n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]   \n",
    ")\n",
    "\n",
    "# Initialize the agent \n",
    "agent = create_tool_calling_agent(\n",
    "    llm,\n",
    "    tools,\n",
    "    prompt\n",
    ")\n",
    "validity_agent = AgentExecutor(agent=agent, tools=tools)\n",
    "\n",
    "key = \"20180627_seq_50m_NC.tif\"\n",
    "# Run the agent. The agent will route the prompt to our NDVI checking tool.\n",
    "result = validity_agent.invoke({\"input\": \"Image: \" + str(key)})\n",
    "print(\"Final agent decision:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
